# ğŸ§ Whisper GPU API with FT Whisper + FastAPI + Docker

This project provides a FastAPI server that uses [ft-whspr]to transcribe audio files using GPU acceleration inside a Docker container.

---

## ğŸš€ Features

- FastAPI server with `/transcribe` endpoint
- Uses `` Whisper model
- GPU acceleration via CUDA 12.6
- Dockerized for portability

---

## ğŸ“ Project Structure

```

whisper\_ft/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md

````

---

## ğŸ”§ Requirements

- **Ubuntu 24.04**
- **NVIDIA GPU** with driver installed
- **CUDA 12.6**
- **Docker**
- **NVIDIA Container Toolkit (with workaround for Ubuntu 24.04)**

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone this repo
```bash
git clone <your-repo-url>
cd whisper_ft
````

---

### 2. âœ… Fix NVIDIA Container Toolkit for Ubuntu 24.04

> NVIDIA's official Docker repos don't yet support Ubuntu 24.04, so we use 22.04 instead.

#### Clean up any broken setup:

```bash
sudo rm /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt clean
sudo apt update
```

#### Install the NVIDIA container toolkit:

```bash
distribution="ubuntu22.04"

curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \
  sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
  sed 's#deb #deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] #' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt update
sudo apt install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

---

### 3. ğŸ§± Build the Docker Image

```bash
docker build -t whisper_ft .
```

---

### 4. â–¶ï¸ Run the API Container with GPU

```bash
docker run --gpus all -p 8000:8000 whisper_ft
```

---

### 5. ğŸ” Call the API

#### POST `/transcribe`

```bash
curl -X POST "http://localhost:8000/transcribe" \
  -H  "accept: application/json" \
  -H  "Content-Type: multipart/form-data" \
  -F "file=@audio.wav"
```

---

## ğŸ“ Example Response

```json
{
  "language": "en",
  "language_probability": 1.0,
  "transcript": "[0.00s -> 3.42s] Hello world, this is a test transcription.\n..."
}
```

---

## ğŸ“¦ Python Dependencies

### `requirements.txt`

```
fastapi
uvicorn[standard]
faster-whisper
```

---

## ğŸ³ Dockerfile Notes

Uses:

```Dockerfile
FROM nvidia/cuda:12.6.2-cudnn-runtime-ubuntu24.04
```

Installs Python, FFmpeg, and your app.

---

## â“Troubleshooting

* `could not select device driver "" with capabilities: [[gpu]]`
  â†’ Install NVIDIA Container Toolkit as shown above.

* `libcudnn_ops.so not found`
  â†’ Use CUDA base image with cuDNN preinstalled (`cudnn-runtime`).

---

## ğŸ“œ License

MIT or as per upstream project licenses.
